# -*- coding: utf-8 -*-
"""Untitled33.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qok9R7E_xjeToT1LJ-GFB6Lap0MJXxct
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs

class KMeansFromScratch:
    def __init__(self, k=3, max_iters=100, tol=1e-4, init='k-means++'):
        self.k = k
        self.max_iters = max_iters
        self.tol = tol
        self.init = init
        self.centroids = None
        self.inertia_ = 0

    def _initialize_centroids(self, X):
        """Initializes centroids using either random selection or K-Means++."""
        if self.init == 'random':
            indices = np.random.choice(len(X), self.k, replace=False)
            return X[indices]
        elif self.init == 'k-means++':
            # K-Means++ logic for better initial placement
            centroids = [X[np.random.choice(len(X))]]
            for _ in range(1, self.k):
                dist_sq = np.array([min([np.sum((c - x)**2) for c in centroids]) for x in X])
                probs = dist_sq / dist_sq.sum()
                centroids.append(X[np.random.choice(len(X), p=probs)])
            return np.array(centroids)

    def fit(self, X):
        """Executes the K-Means algorithm: Assignment and Update steps."""
        self.centroids = self._initialize_centroids(X)

        for i in range(self.max_iters):
            # Assignment Step: Calculate Euclidean distance using broadcasting
            distances = np.linalg.norm(X[:, np.newaxis] - self.centroids, axis=2)
            labels = np.argmin(distances, axis=1)

            # Update Step: Re-calculate centroids based on the mean of cluster points
            new_centroids = np.array([X[labels == j].mean(axis=0) if len(X[labels == j]) > 0
                                      else self.centroids[j] for j in range(self.k)])

            # Convergence Check: Stop if centroids shift less than the defined tolerance
            if np.all(np.abs(new_centroids - self.centroids) < self.tol):
                break
            self.centroids = new_centroids

        # Calculate final inertia (WCSS) for the Elbow Method
        final_distances = np.linalg.norm(X[:, np.newaxis] - self.centroids, axis=2)
        self.inertia_ = np.sum(np.min(final_distances, axis=1)**2)
        return labels

# --- Task 2: Synthetic Data Generation ---
X, _ = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=0)

# --- Task 3 & 4: Elbow Method and WCSS Output (Deliverable 2) ---
print("--- WCSS Values for Elbow Method (Deliverable 2) ---")
inertias = []
k_range = range(1, 11)
for k in k_range:
    model = KMeansFromScratch(k=k, init='k-means++')
    model.fit(X)
    inertias.append(model.inertia_)
    print(f"K={k}: WCSS={model.inertia_:.2f}")

# --- Task 5: Final Visualization ---
plt.figure(figsize=(12, 5))

# Elbow Plot
plt.subplot(1, 2, 1)
plt.plot(k_range, inertias, 'bx-')
plt.xlabel('Number of clusters (K)')
plt.ylabel('WCSS (Inertia)')
plt.title('Elbow Method for Optimal K')

# Final Clustering Results with Optimal K=4
optimal_k = 4
model = KMeansFromScratch(k=optimal_k, init='k-means++')
labels = model.fit(X)
plt.subplot(1, 2, 2)
plt.scatter(X[:, 0], X[:, 1], c=labels, s=30, cmap='viridis')
plt.scatter(model.centroids[:, 0], model.centroids[:, 1], c='red', marker='X', s=200, label='Centroids')
plt.title(f'Final Clustering Result (K={optimal_k})')
plt.legend()
plt.tight_layout()
plt.show()